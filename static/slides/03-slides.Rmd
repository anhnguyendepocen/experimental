---
title: "One way ANOVA"
author: "Léo Belzile"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: "libs"
    chakra: "libs/remark-latest.min.js"
    css: ["default", "css/ath-slides.css", "css/ath-inferno-fonts.css", "css/animate.css"]
    seal: false
    anchor_sections: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = "center")
```
```{r packages-data, echo = FALSE, include=FALSE}
library(tidyverse)
library(patchwork)
```
```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view","freezeframe","panelset","clipboard"))
xaringanExtra::use_broadcast()
```

class: center middle main-title section-title-1

# One way ANOVA

.class-info[

**Session 3**

.light[MATH 80667A: Experimental Design and Statistical Methods <br>for Quantitative Research in Management <br>
HEC Montréal
]

]

---

name: outline
class: title title-inv-2

# Outline
--


.box-2.medium.sp-after-half[Hypothesis tests for ANOVA]

--

.box-4.medium.sp-after-half[Parametrizations and interpretation]

--

.box-3.medium.sp-after-half[Planned comparisons and *post-hoc* tests]


---

layout: false
name: recap
class: center middle section-title section-title-2 animated fadeIn

# Hypothesis tests for ANOVA

---

class: title title-2

# General recipe of hypothesis testing

.box-2.small.sp-after-half[(1) Define variables]
.box-2.small.sp-after-half[(2) Write down hypotheses]
.box-2.small.sp-after-half[(3) Choose/compute a test statistic]
.box-2.small.sp-after-half[(4) Compare statistic to null distribution]
.box-2.small.sp-after-half[(5) Compute _p_-value / confidence interval]
.box-2.small.sp-after-half[(6) Conclude (reject/fail to reject)]

---

class: title title-2

# Level = probability of condemning an innocent

.box-2.sp-after-half.large[
Fix **level** $\alpha$
**before** the experiment.
]

.box-inv-2.sp-after-half.large[

Choose small $\alpha$ (typical value is 5%)
]


.box-2.sp-after-half.large[
Reject $\mathscr{H}_0$ if p-value less than $\alpha$
]


???

Question: why can't we fix $\alpha=0$?



---

class: title title-2

# F-test for one way ANOVA

.box-inv-2.medium[Global null hypothesis]

No difference between treatments

- $\mathscr{H}_0$ (null): all of the $K$ treatment groups have the same average $\mu$
- $\mathscr{H}_a$ (alternative): at least two treatments have different averages

???

- The null hypothesis can be viewed as a special case from a bigger class of possibilities
- it always corresponds to some restrictions from the alternative class

---

class: title title-2

# Building a statistic

.small[
Denote
- $y_{ik}$ is observation $i$ of group $k$
- $\widehat{\mu}_1, \ldots, \widehat{\mu}_K$ the sample average of groups $1, \ldots, K$
- $\widehat{\mu}$ is overall sample mean

]

.box-2[Decomposing variability into bits]

\begin{align*}
\underset{\text{total sum of squares}}{\sum_{i}\sum_{k} (y_{ik} - \widehat{\mu})^2} &= \underset{\text{within sum of squares}}{\sum_i \sum_k (y_{ik} - \widehat{\mu}_k)^2} +  \underset{\text{between sum of squares}}{\sum_k n_i (\widehat{\mu}_k - \widehat{\mu})^2}.
\end{align*}

.pull-left-3[
.box-inv-2[null model]
]
.pull-middle-3[
.box-inv-2[alternative model]
]
.pull-right-3[
.box-inv-2[added variability]
]

---


class: title title-2

# Degrees of freedom

The parameters of the null distribution are called **degrees of freedom**

- $K-1$ is the number of constraints imposed by the null
- $n-K$ is the number of observations minus number of mean parameters estimated under alternative

---

class: title title-2

# _F_-test statistic

.box-2.medium[Omnibus test]

With $K$ groups and $n$ observations, the statistic is

\begin{align*}
F =  \frac{\text{between sum of squares}/(K-1)}{\text{within sum of squares}/(n-K)}
\end{align*}


The null distribution (benchmark) is $\mathsf{F}(K-1, n-K)$.

---

class: title title-2

# Intuition behind _F_-test

Idea of _F_-statistic: under the null, both numerator and denominator are estimators of the variance.

- the $F$ ratio should be approximately one on average
- the numerator is more variable (so skewed null distribution)...


---

class: title title-2

# Pairwise differences and _t_-tests


The pairwise differences (_p_-values) and confidence intervals for groups $j$ and $k$ are based on the _t_-statistic:

\begin{align*}
t = \frac{\text{estimated} - \text{postulated difference}}{\text{uncertainty}}= \frac{(\widehat{\mu}_j - \widehat{\mu}_k) - (\mu_j - \mu_k)}{\mathsf{se}(\widehat{\mu}_j - \widehat{\mu}_k)}
\end{align*}
which has a Student-_t_ null distribution, denoted $\mathsf{St}(n-k)$.

The standard error $\mathsf{se}(\widehat{\mu}_j - \widehat{\mu}_k)$ uses the pooled variance estimate (based on all groups).

---

class: title title-2

# _t_-tests

If we postulate $\delta_{jk} = \mu_j - \mu_k = 0$, the test statistic becomes

\begin{align*}
t = \frac{\widehat{\delta}_{jk} - 0}{\mathsf{se}(\widehat{\delta}_{jk})}
\end{align*}

The $p$-value is $p = 1- \Pr(-|t| \leq T \leq |t|)$ for $T \sim \mathsf{St}_{n-k}$.
   - probability of statistic being more extreme than $t$


The larger the values of $t$ (positive or negative), the more evidence against the null hypothesis.
---
class: title title-2
# Example

Consider the pairwise average difference in scores between the praised (group C) and the reproved (group D) of the `arithmetic` study.


- Sample averages are $\widehat{\mu}_C = 27.4$ and $\widehat{\mu}_D = 23.4$
- The estimated pooled standard deviation for the five groups is $1.15$
- The estimated average difference between groups $C$ and $D$ is $\widehat{\delta}_{CD} = 4$.
- The standard error for the difference is $\mathsf{se}(\widehat{\delta}_{CD}) = 1.6216$
---
class: title title-2
# Example

- If $\mathscr{H}_0: \delta_{CD}=0$, the $t$ statistic is 
$$t=\frac{\widehat{\delta}_{CD} - 0}{\mathsf{se}(\widehat{\delta}_{CD})} = \frac{4}{1.6216}=2.467$$
- The $p$-value is $p=0.018$. 
- We reject the null at level $\alpha=5$% since $0.018 < 0.05$.
- Conclude that there is a significant difference at level $\alpha=0.05$ between the average scores of subpopulations $C$ and $D$.


---

class: title title-2
# Null distribution


The blue area defines the set of values for which we fail to reject null $\mathscr{H}_0$.

All values of $t$ falling in the red aread lead to rejection at level $5$%.

```{r tcurve, eval = TRUE, echo = FALSE, retina = 3, out.width = '60%', fig.asp = 0.618}
ggplot() +
  coord_cartesian(xlim = c(-5,5), 
                  ylim = c(0, 0.5), 
                  expand = FALSE) +
  stat_function(fun = dt, 
                args = list(df = 40), 
                xlim = c(qt(0.975, df = 40),5),
                geom = "area", 
                fill = "red", 
                alpha = 0.2) +
    stat_function(fun = dt, 
                args = list(df = 40), 
                xlim = c(-5, qt(0.025, df = 40)),
                geom = "area", 
                fill = "red", 
                alpha = 0.2) +
    stat_function(fun = dt, 
                args = list(df = 40), 
                xlim = c(qt(0.025, df = 40), qt(0.975, df = 40)),
                geom = "area", 
                fill = "blue", 
                alpha = 0.2) + 
    stat_function(fun = dt, 
    xlim = c(-5,5),
                args = list(df = 40), n = 1000) + 
       theme_classic() + labs(y = "density", x = "")
```


---

class: title title-2
# Critical values

For a test at level $\alpha$ (two-sided), fail to reject all values of the test statistic $t$ that are in interval

$$\mathfrak{t}_{n-k}(\alpha/2) \leq t \leq \mathfrak{t}_{n-k}(1-\alpha/2)$$

Because of symmetry around zero, $\mathfrak{t}_{n-k}(1-\alpha/2) = -\mathfrak{t}_{n-k}(\alpha/2)$.

- We call $\mathfrak{t}_{n-k}(1-\alpha/2)$ a **critical value**. 
- in **R**, `qt(1-alpha/2, df = n - k)` where `n` is the number of observations and `k` the number of groups

---
class: title title-2
# Confidence interval 

.small[

Let $\delta_{jk}=\mu_j - \mu_k$ denote the population difference, $\widehat{\delta}_{jk}$ the estimated difference (difference in sample averages) and $\mathsf{se}(\widehat{\delta}_{jk})$ the estimated standard error.

The region for which we fail to reject the null is 
\begin{align*}
\mathfrak{t}_{n-k}(\alpha/2) \leq  \frac{\widehat{\delta}_{jk} - \delta_{jk}}{\mathsf{se}(\widehat{\delta}_{jk})} \leq \mathfrak{t}_{n-k}(1-\alpha/2)
\end{align*}
which rearranged gives the $(1-\alpha)$ confidence interval for the (unknown) difference $\delta_{jk}$.

\begin{align*}
\widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(\alpha/2) \leq \delta_{jk} \leq \widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(1-\alpha/2)
\end{align*}

]

---
class: title title-2

# Interpretation of confidence intervals

The reported confidence interval is $$[\widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(\alpha/2), \widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(1-\alpha/2)].$$
.small[
Each bound is of the form

$$ \text{estimate} + \text{critical value} \times \text{standard error}$$

]
.box-2.sp-after-half[ confidence interval = [lower, upper] units]


If we replicate the experiment and compute confidence intervals each time
- on average, 95% of those intervals will contain the true value if the assumptions underlying the model are met.


---
class: title title-2

# Interpretation in a picture: coin toss analogy
.small[
Each interval either contains the true value (black horizontal line) or doesn't.
]
```{r out.width = '70%', fig.asp = 0.618, fig.alt = "100 confidence intervals", eval = TRUE, echo = FALSE, cache = TRUE}
set.seed(1234)
interv <- t(sapply(1:100, function(i){t.test(rnorm(1000), mu=0)$conf.int}))
confint_dat <- data.frame(lower = interv[,1],
                          upper = interv[,2],
                          replicate = 1:100,
                          covers = factor((interv[,1] > 0) | (interv[,2] < 0), labels = c("covers","fails to cover")))
ggplot(data = confint_dat,
       aes(x = factor(replicate))) +
  geom_hline(yintercept = 0) +
  geom_segment(mapping = aes(y = lower, 
                             yend = upper, 
                             x = replicate, 
                             xend = replicate,
                             col = covers), 
               alpha = 0.5) +
  scale_color_discrete(type = c("blue","red")) +
  labs(x = "replicate study",
       y = "",
       col = "") +
  theme_classic() + 
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
```
---



class: title title-2

# Why confidence intervals?

Test statistics are standardized, 
- Good for comparisons with benchmark
- typically meaningless (standardized = unitless quantities)

Two options for reporting: 

- $p$-value: probability of more extreme outcome if no mean difference
- confidence intervals: set of all values for which we fail to reject the null hypothesis at level $\alpha$ for the given sample


---
class: title title-2
# Example


- Mean difference of $\widehat{\delta}_{CD}=4$,  with $\mathsf{se}(\widehat{\delta}_{CD})=1.6216$.
- The critical values for a test at level $\alpha = 5$% are $-2.021$ and $2.021$ 
   - `qt(0.975, df = 45 - 5)`
- Since $|t| > 2.021$, reject $\mathscr{H}_0$: the two population are statistically significant at level $\alpha=5$%.
- The confidence interval is $$[4-1.6216\times 2.021, 4+1.6216\times 2.021] = [0.723, 7.28]$$

The postulated value $\delta_{CD}=0$ is not in the interval: reject $\mathscr{H}_0$.

---
class: title title-2

# Pairwise differences in **R**

```{r pairdiff, echo = TRUE, eval = FALSE}
library(tidyverse) # data manipulation
library(emmeans) # marginal means and contrasts
url <- "https://edsm.rbind.io/data/arithmetic.csv" 
# load data, define column type (factor and integer)
arithmetic <- read_csv(url, col_types = "fi") 
# fit one-way ANOVA model
model <- lm(score ~ group, data = arithmetic)
# Compute average of groups with model specification
margmeans <- emmeans::emmeans(model, specs = "group")
# Contrasts (default to pairwise comparisons) - no adjustment
contrast(margmeans, adjust = 'none', infer = TRUE) 
#infer = TRUE for confidence intervals
```

---

layout: false
name: parametrization
class: center middle section-title section-title-4 animated fadeIn

# Parametrizations and interpretation

---

class: title title-4

# Parametrization 1: sample averages

Most natural parametrization, not useful for test

- Sample sizes in each group: $n_1, \ldots, n_K$, are known.

- sample average of each treatment group: $\widehat{\mu}_1, \ldots, \widehat{\mu}_K$.

.box-inv-4.sp-after-half[
$K$ means  = $K$ parameters
]

Overall mean is 
\begin{align*}
n \widehat{\mu} = n_1 \widehat{\mu}_1 + \cdots + n_K \widehat{\mu}_K
\end{align*}


---
class: title title-4

# Parametrization 2: contrasts

In terms of differences, relative to a baseline category $j$



- Intercept = sample mean $\widehat{\mu}_j$
- Coefficient for group $k \neq j$: $\widehat{\mu}_k - \widehat{\mu}_j$
    - difference between averages of group $k$ and baseline

In **R**, the baseline is the smallest alphanumerical value.

.box-inv-4[
```{r echo = TRUE, eval = FALSE}
lm(response ~ group)
```
]

---
class: title title-4

# Parametrization 3: sum-to-zero

In terms of differences, relative to average of $\widehat{\mu}_1, \ldots, \widehat{\mu}_K$

- Intercept = $(\widehat{\mu}_1 + \cdots + \widehat{\mu}_K)/K$
- Coefficient for group $k$: $\widehat{\mu}_k$ minus intercept

In **R**, the last factor level is dropped by default.

.box-inv-4[
```{r echo = TRUE, eval = FALSE}
lm(response ~ group, contrasts = contr.sum(group))
```
]

Warning: Intercept $\neq \widehat{\mu}$ unless the sample is balanced.

---
class: title title-4

# Comparison for the arithmetic example


<table>
 <thead>
  <tr>
   <th style="text-align:left;"> group </th>
   <th style="text-align:right;"> mean </th>
   <th style="text-align:right;"> contrasts </th>
   <th style="text-align:right;"> sum-to-zero </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> intercept </td>
   <td style="text-align:right;">  </td>
   <td style="text-align:right;"> 19.66 </td>
   <td style="text-align:right;"> 21.00 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> control 1 </td>
   <td style="text-align:right;"> 19.66 </td>
   <td style="text-align:right;">  </td>
   <td style="text-align:right;"> -1.33 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> control 2 </td>
   <td style="text-align:right;"> 18.33 </td>
   <td style="text-align:right;"> -1.33 </td>
   <td style="text-align:right;"> -2.66 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> praised </td>
   <td style="text-align:right;"> 27.44 </td>
   <td style="text-align:right;"> 7.77 </td>
   <td style="text-align:right;"> 6.44 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> reproved </td>
   <td style="text-align:right;"> 23.44 </td>
   <td style="text-align:right;"> 3.77 </td>
   <td style="text-align:right;"> 2.44 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> ignored </td>
   <td style="text-align:right;"> 16.11 </td>
   <td style="text-align:right;"> -3.55 </td>
   <td style="text-align:right;">  </td>
  </tr>
</tbody>
</table>

---
layout: false
name: planned-comparisons
class: center middle section-title section-title-3 animated fadeIn

# Planned comparisons and post-hoc tests

---

class: title title-3

# Planned comparisons

Oftentimes, we are not interested in the global null hypothesis.

- Can formulate planned comparisons *at registration time* for effects of interest

.box-inv-3.large[What is the scientific question of interest?]

---

class: title title-3

# Arithmetic example

.box-3.medium[Setup]
.pull-left-3[
.box-inv-3[
group 1 
]
.center[
(control)
]
]
.pull-middle-3[
.box-inv-3.sp-after-half[
group 2 
]
.center[
(control)
]
]

.pull-right-3[
.box-inv-3.sp-after-half[
group 3
]
.center[
(praise, reprove, ignore)
]
]

--

.box-3.medium[Hypothesis of interest]

- $\mathscr{H}_{01}$: $\mu_{\text{praise}} = \mu_{\text{reproved}}$ (attention)
- $\mathscr{H}_{02}$: $\frac{1}{2}(\mu_{\text{control}_1}+\mu_{\text{control}_2}) = \mu_{\text{praised}}$ (encouragement)

???

This is post-hoc, but supposed we had particular interest in the following hypothesis (for illustration purposes)

---

class: title title-3

# Contrasts

With placeholders for each group, write
$\mathscr{H}_{01}: \mu_{\text{praised}} = \mu_{\text{reproved}}$ as 
.small.center[

$0\cdot \mu_{\text{control}_1}$ + $0\cdot \mu_{\text{control}_2}$ + $1 \cdot \mu_{\text{praised}}$ - $1\cdot \mu_{\text{reproved}}$ + $0 \cdot \mu_{\text{ignored}}$

]

The sum of the coefficients, $(0, 0, 1, -1, 0)$, is zero.

.box-3[Contrast = sum-to-zero constraint]

--

Similarly, for $\mathscr{H}_{02}: \frac{1}{2}(\mu_{\text{control}_1}+\mu_{\text{control}_2}) = \mu_{\text{praise}}$
.small.center[

$\frac{1}{2} \cdot \mu_{\text{control}_1}$ + $\frac{1}{2}\cdot \mu_{\text{control}_2}$ - $1 \cdot \mu_{\text{praised}}$ + $0\cdot \mu_{\text{reproved}}$ + $0 \cdot \mu_{\text{ignored}}$

]

The entries of the contrast vector $\left(\frac{1}{2}, \frac{1}{2}, -1, 0, 0\right)$ sum to zero.

Equivalent formulation is obtained by picking $(1,1,-2,0,0)$

---
class: title title-3

# Contrasts in **R**

```{r eval = FALSE, echo = TRUE}
library(emmeans)
linmod <- lm(score ~ group, data = arithmetic)
linmod_emm <- emmeans(linmod, specs = 'group')
contrast_specif <- list(
  controlvspraised = c(0.5, 0.5, -1, 0, 0),
  praisedvsreproved = c(0, 0, 1, -1, 0)
)
contrasts_res <- 
  contrast(object = linmod_emm, 
                    method = contrast_specif)
# Obtain confidence intervals instead of p-values
confint(contrasts_res)
```

---


class: title title-3

# *Post-hoc* tests

Maybe there is some difference between groups?

Unplanned comparisons: go fishing...

.box-inv-3[
Comparing all pairwise differences = $\binom{K}{2}$ tests]

With $K=5$ groups, we get 10 pairwise comparisons.

```{r eval = FALSE}
emmeans(modlin, pairwise ~ group)
```

If there were no differences between the groups, how many do we expect to find significant by chance with $\alpha = 0.1$?


