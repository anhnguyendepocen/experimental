<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>One way ANOVA</title>
    <meta charset="utf-8" />
    <meta name="author" content="Léo Belzile" />
    <meta name="date" content="2021-11-27" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/freezeframe-5.0.2/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe-0.0.1/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link rel="stylesheet" href="css/ath-slides.css" type="text/css" />
    <link rel="stylesheet" href="css/ath-inferno-fonts.css" type="text/css" />
    <link rel="stylesheet" href="css/animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






class: center middle main-title section-title-1

# One way ANOVA

.class-info[

**Session 3**

.light[MATH 80667A: Experimental Design and Statistical Methods &lt;br&gt;for Quantitative Research in Management &lt;br&gt;
HEC Montréal
]

]

---

name: outline
class: title title-inv-2

# Outline
--


.box-2.medium.sp-after-half[Hypothesis tests for ANOVA]

--

.box-4.medium.sp-after-half[Parametrizations and interpretation]

--

.box-3.medium.sp-after-half[Planned comparisons and *post-hoc* tests]


---

layout: false
name: recap
class: center middle section-title section-title-2 animated fadeIn

# Hypothesis tests for ANOVA

---

class: title title-2

# General recipe of hypothesis testing

.box-2.small.sp-after-half[(1) Define variables]
.box-2.small.sp-after-half[(2) Write down hypotheses]
.box-2.small.sp-after-half[(3) Choose/compute a test statistic]
.box-2.small.sp-after-half[(4) Compare statistic to null distribution]
.box-2.small.sp-after-half[(5) Compute _p_-value / confidence interval]
.box-2.small.sp-after-half[(6) Conclude (reject/fail to reject)]

---

class: title title-2

# Level = probability of condemning an innocent

.box-2.sp-after-half.large[
Fix **level** `\(\alpha\)`
**before** the experiment.
]

.box-inv-2.sp-after-half.large[

Choose small `\(\alpha\)` (typical value is 5%)
]


.box-2.sp-after-half.large[
Reject `\(\mathscr{H}_0\)` if p-value less than `\(\alpha\)`
]


???

Question: why can't we fix `\(\alpha=0\)`?



---

class: title title-2

# F-test for one way ANOVA

.box-inv-2.medium[Global null hypothesis]

No difference between treatments

- `\(\mathscr{H}_0\)` (null): all of the `\(K\)` treatment groups have the same average `\(\mu\)`
- `\(\mathscr{H}_a\)` (alternative): at least two treatments have different averages

???

- The null hypothesis can be viewed as a special case from a bigger class of possibilities
- it always corresponds to some restrictions from the alternative class

---

class: title title-2

# Building a statistic

.small[
Denote
- `\(y_{ik}\)` is observation `\(i\)` of group `\(k\)`
- `\(\widehat{\mu}_1, \ldots, \widehat{\mu}_K\)` the sample average of groups `\(1, \ldots, K\)`
- `\(\widehat{\mu}\)` is overall sample mean

]

.box-2[Decomposing variability into bits]

`\begin{align*}
\underset{\text{total sum of squares}}{\sum_{i}\sum_{k} (y_{ik} - \widehat{\mu})^2} &amp;= \underset{\text{within sum of squares}}{\sum_i \sum_k (y_{ik} - \widehat{\mu}_k)^2} +  \underset{\text{between sum of squares}}{\sum_k n_i (\widehat{\mu}_k - \widehat{\mu})^2}.
\end{align*}`

.pull-left-3[
.box-inv-2[null model]
]
.pull-middle-3[
.box-inv-2[alternative model]
]
.pull-right-3[
.box-inv-2[added variability]
]

---


class: title title-2

# Degrees of freedom

The parameters of the null distribution are called **degrees of freedom**

- `\(K-1\)` is the number of constraints imposed by the null
- `\(n-K\)` is the number of observations minus number of mean parameters estimated under alternative

---

class: title title-2

# _F_-test statistic

.box-2.medium[Omnibus test]

With `\(K\)` groups and `\(n\)` observations, the statistic is

`\begin{align*}
F =  \frac{\text{between sum of squares}/(K-1)}{\text{within sum of squares}/(n-K)}
\end{align*}`


The null distribution (benchmark) is `\(\mathsf{F}(K-1, n-K)\)`.

---

class: title title-2

# Intuition behind _F_-test

Idea of _F_-statistic: under the null, both numerator and denominator are estimators of the variance.

- the `\(F\)` ratio should be approximately one on average
- the numerator is more variable (so skewed null distribution)...


---

class: title title-2

# Pairwise differences and _t_-tests


The pairwise differences (_p_-values) and confidence intervals for groups `\(j\)` and `\(k\)` are based on the _t_-statistic:

`\begin{align*}
t = \frac{\text{estimated} - \text{postulated difference}}{\text{uncertainty}}= \frac{(\widehat{\mu}_j - \widehat{\mu}_k) - (\mu_j - \mu_k)}{\mathsf{se}(\widehat{\mu}_j - \widehat{\mu}_k)}
\end{align*}`
which has a Student-_t_ null distribution, denoted `\(\mathsf{St}(n-k)\)`.

The standard error `\(\mathsf{se}(\widehat{\mu}_j - \widehat{\mu}_k)\)` uses the pooled variance estimate (based on all groups).

---

class: title title-2

# _t_-tests

If we postulate `\(\delta_{jk} = \mu_j - \mu_k = 0\)`, the test statistic becomes

`\begin{align*}
t = \frac{\widehat{\delta}_{jk} - 0}{\mathsf{se}(\widehat{\delta}_{jk})}
\end{align*}`

The `\(p\)`-value is `\(p = 1- \Pr(-|t| \leq T \leq |t|)\)` for `\(T \sim \mathsf{St}_{n-k}\)`.
   - probability of statistic being more extreme than `\(t\)`


The larger the values of `\(t\)` (positive or negative), the more evidence against the null hypothesis.
---
class: title title-2
# Example

Consider the pairwise average difference in scores between the praised (group C) and the reproved (group D) of the `arithmetic` study.


- Sample averages are `\(\widehat{\mu}_C = 27.4\)` and `\(\widehat{\mu}_D = 23.4\)`
- The estimated pooled standard deviation for the five groups is `\(1.15\)`
- The estimated average difference between groups `\(C\)` and `\(D\)` is `\(\widehat{\delta}_{CD} = 4\)`.
- The standard error for the difference is `\(\mathsf{se}(\widehat{\delta}_{CD}) = 1.6216\)`
---
class: title title-2
# Example

- If `\(\mathscr{H}_0: \delta_{CD}=0\)`, the `\(t\)` statistic is 
`$$t=\frac{\widehat{\delta}_{CD} - 0}{\mathsf{se}(\widehat{\delta}_{CD})} = \frac{4}{1.6216}=2.467$$`
- The `\(p\)`-value is `\(p=0.018\)`. 
- We reject the null at level `\(\alpha=5\)`% since `\(0.018 &lt; 0.05\)`.
- Conclude that there is a significant difference at level `\(\alpha=0.05\)` between the average scores of subpopulations `\(C\)` and `\(D\)`.


---

class: title title-2
# Null distribution


The blue area defines the set of values for which we fail to reject null `\(\mathscr{H}_0\)`.

All values of `\(t\)` falling in the red aread lead to rejection at level `\(5\)`%.

&lt;img src="03-slides_files/figure-html/tcurve-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---

class: title title-2
# Critical values

For a test at level `\(\alpha\)` (two-sided), fail to reject all values of the test statistic `\(t\)` that are in interval

`$$\mathfrak{t}_{n-k}(\alpha/2) \leq t \leq \mathfrak{t}_{n-k}(1-\alpha/2)$$`

Because of symmetry around zero, `\(\mathfrak{t}_{n-k}(1-\alpha/2) = -\mathfrak{t}_{n-k}(\alpha/2)\)`.

- We call `\(\mathfrak{t}_{n-k}(1-\alpha/2)\)` a **critical value**. 
- in **R**, `qt(1-alpha/2, df = n - k)` where `n` is the number of observations and `k` the number of groups

---
class: title title-2
# Confidence interval 

.small[

Let `\(\delta_{jk}=\mu_j - \mu_k\)` denote the population difference, `\(\widehat{\delta}_{jk}\)` the estimated difference (difference in sample averages) and `\(\mathsf{se}(\widehat{\delta}_{jk})\)` the estimated standard error.

The region for which we fail to reject the null is 
`\begin{align*}
\mathfrak{t}_{n-k}(\alpha/2) \leq  \frac{\widehat{\delta}_{jk} - \delta_{jk}}{\mathsf{se}(\widehat{\delta}_{jk})} \leq \mathfrak{t}_{n-k}(1-\alpha/2)
\end{align*}`
which rearranged gives the `\((1-\alpha)\)` confidence interval for the (unknown) difference `\(\delta_{jk}\)`.

`\begin{align*}
\widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(\alpha/2) \leq \delta_{jk} \leq \widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(1-\alpha/2)
\end{align*}`

]

---
class: title title-2

# Interpretation of confidence intervals

The reported confidence interval is `$$[\widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(\alpha/2), \widehat{\delta}_{jk} + \mathsf{se}(\widehat{\delta}_{jk})\mathfrak{t}_{n-k}(1-\alpha/2)].$$`
.small[
Each bound is of the form

$$ \text{estimate} + \text{critical value} \times \text{standard error}$$

]
.box-2.sp-after-half[ confidence interval = [lower, upper] units]


If we replicate the experiment and compute confidence intervals each time
- on average, 95% of those intervals will contain the true value if the assumptions underlying the model are met.


---
class: title title-2

# Interpretation in a picture: coin toss analogy
.small[
Each interval either contains the true value (black horizontal line) or doesn't.
]
&lt;img src="03-slides_files/figure-html/unnamed-chunk-1-1.png" title="100 confidence intervals" alt="100 confidence intervals" width="70%" style="display: block; margin: auto;" /&gt;
---



class: title title-2

# Why confidence intervals?

Test statistics are standardized, 
- Good for comparisons with benchmark
- typically meaningless (standardized = unitless quantities)

Two options for reporting: 

- `\(p\)`-value: probability of more extreme outcome if no mean difference
- confidence intervals: set of all values for which we fail to reject the null hypothesis at level `\(\alpha\)` for the given sample


---
class: title title-2
# Example


- Mean difference of `\(\widehat{\delta}_{CD}=4\)`,  with `\(\mathsf{se}(\widehat{\delta}_{CD})=1.6216\)`.
- The critical values for a test at level `\(\alpha = 5\)`% are `\(-2.021\)` and `\(2.021\)` 
   - `qt(0.975, df = 45 - 5)`
- Since `\(|t| &gt; 2.021\)`, reject `\(\mathscr{H}_0\)`: the two population are statistically significant at level `\(\alpha=5\)`%.
- The confidence interval is `$$[4-1.6216\times 2.021, 4+1.6216\times 2.021] = [0.723, 7.28]$$`

The postulated value `\(\delta_{CD}=0\)` is not in the interval: reject `\(\mathscr{H}_0\)`.

---
class: title title-2

# Pairwise differences in **R**


```r
library(tidyverse) # data manipulation
library(emmeans) # marginal means and contrasts
url &lt;- "https://edsm.rbind.io/data/arithmetic.csv" 
# load data, define column type (factor and integer)
arithmetic &lt;- read_csv(url, col_types = "fi") 
# fit one-way ANOVA model
model &lt;- lm(score ~ group, data = arithmetic)
# Compute average of groups with model specification
margmeans &lt;- emmeans::emmeans(model, specs = "group")
# Contrasts (default to pairwise comparisons) - no adjustment
contrast(margmeans, adjust = 'none', infer = TRUE) 
#infer = TRUE for confidence intervals
```

---

layout: false
name: parametrization
class: center middle section-title section-title-4 animated fadeIn

# Parametrizations and interpretation

---

class: title title-4

# Parametrization 1: sample averages

Most natural parametrization, not useful for test

- Sample sizes in each group: `\(n_1, \ldots, n_K\)`, are known.

- sample average of each treatment group: `\(\widehat{\mu}_1, \ldots, \widehat{\mu}_K\)`.

.box-inv-4.sp-after-half[
`\(K\)` means  = `\(K\)` parameters
]

Overall mean is 
`\begin{align*}
n \widehat{\mu} = n_1 \widehat{\mu}_1 + \cdots + n_K \widehat{\mu}_K
\end{align*}`


---
class: title title-4

# Parametrization 2: contrasts

In terms of differences, relative to a baseline category `\(j\)`



- Intercept = sample mean `\(\widehat{\mu}_j\)`
- Coefficient for group `\(k \neq j\)`: `\(\widehat{\mu}_k - \widehat{\mu}_j\)`
    - difference between averages of group `\(k\)` and baseline

In **R**, the baseline is the smallest alphanumerical value.

.box-inv-4[

```r
lm(response ~ group)
```
]

---
class: title title-4

# Parametrization 3: sum-to-zero

In terms of differences, relative to average of `\(\widehat{\mu}_1, \ldots, \widehat{\mu}_K\)`

- Intercept = `\((\widehat{\mu}_1 + \cdots + \widehat{\mu}_K)/K\)`
- Coefficient for group `\(k\)`: `\(\widehat{\mu}_k\)` minus intercept

In **R**, the last factor level is dropped by default.

.box-inv-4[

```r
lm(response ~ group, contrasts = contr.sum(group))
```
]

Warning: Intercept `\(\neq \widehat{\mu}\)` unless the sample is balanced.

---
class: title title-4

# Comparison for the arithmetic example


&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; group &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; mean &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; contrasts &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; sum-to-zero &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; intercept &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19.66 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 21.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; control 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19.66 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.33 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; control 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.33 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.33 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.66 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; praised &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.77 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6.44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; reproved &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 23.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.77 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ignored &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.11 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.55 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
layout: false
name: planned-comparisons
class: center middle section-title section-title-3 animated fadeIn

# Planned comparisons and post-hoc tests

---

class: title title-3

# Planned comparisons

Oftentimes, we are not interested in the global null hypothesis.

- Can formulate planned comparisons *at registration time* for effects of interest

.box-inv-3.large[What is the scientific question of interest?]

---

class: title title-3

# Arithmetic example

.box-3.medium[Setup]
.pull-left-3[
.box-inv-3[
group 1 
]
.center[
(control)
]
]
.pull-middle-3[
.box-inv-3.sp-after-half[
group 2 
]
.center[
(control)
]
]

.pull-right-3[
.box-inv-3.sp-after-half[
group 3
]
.center[
(praise, reprove, ignore)
]
]

--

.box-3.medium[Hypothesis of interest]

- `\(\mathscr{H}_{01}\)`: `\(\mu_{\text{praise}} = \mu_{\text{reproved}}\)` (attention)
- `\(\mathscr{H}_{02}\)`: `\(\frac{1}{2}(\mu_{\text{control}_1}+\mu_{\text{control}_2}) = \mu_{\text{praised}}\)` (encouragement)

???

This is post-hoc, but supposed we had particular interest in the following hypothesis (for illustration purposes)

---

class: title title-3

# Contrasts

With placeholders for each group, write
`\(\mathscr{H}_{01}: \mu_{\text{praised}} = \mu_{\text{reproved}}\)` as 
.small.center[

`\(0\cdot \mu_{\text{control}_1}\)` + `\(0\cdot \mu_{\text{control}_2}\)` + `\(1 \cdot \mu_{\text{praised}}\)` - `\(1\cdot \mu_{\text{reproved}}\)` + `\(0 \cdot \mu_{\text{ignored}}\)`

]

The sum of the coefficients, `\((0, 0, 1, -1, 0)\)`, is zero.

.box-3[Contrast = sum-to-zero constraint]

--

Similarly, for `\(\mathscr{H}_{02}: \frac{1}{2}(\mu_{\text{control}_1}+\mu_{\text{control}_2}) = \mu_{\text{praise}}\)`
.small.center[

`\(\frac{1}{2} \cdot \mu_{\text{control}_1}\)` + `\(\frac{1}{2}\cdot \mu_{\text{control}_2}\)` - `\(1 \cdot \mu_{\text{praised}}\)` + `\(0\cdot \mu_{\text{reproved}}\)` + `\(0 \cdot \mu_{\text{ignored}}\)`

]

The entries of the contrast vector `\(\left(\frac{1}{2}, \frac{1}{2}, -1, 0, 0\right)\)` sum to zero.

Equivalent formulation is obtained by picking `\((1,1,-2,0,0)\)`

---
class: title title-3

# Contrasts in **R**


```r
library(emmeans)
linmod &lt;- lm(score ~ group, data = arithmetic)
linmod_emm &lt;- emmeans(linmod, specs = 'group')
contrast_specif &lt;- list(
  controlvspraised = c(0.5, 0.5, -1, 0, 0),
  praisedvsreproved = c(0, 0, 1, -1, 0)
)
contrasts_res &lt;- 
  contrast(object = linmod_emm, 
                    method = contrast_specif)
# Obtain confidence intervals instead of p-values
confint(contrasts_res)
```

---


class: title title-3

# *Post-hoc* tests

Maybe there is some difference between groups?

Unplanned comparisons: go fishing...

.box-inv-3[
Comparing all pairwise differences = `\(\binom{K}{2}\)` tests]

With `\(K=5\)` groups, we get 10 pairwise comparisons.


```r
emmeans(modlin, pairwise ~ group)
```

If there were no differences between the groups, how many do we expect to find significant by chance with `\(\alpha = 0.1\)`?


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
