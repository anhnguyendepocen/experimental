<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Effect size and power</title>
    <meta charset="utf-8" />
    <meta name="author" content="Léo Belzile" />
    <meta name="date" content="2021-10-08" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/freezeframe-5.0.2/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe-0.0.1/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link rel="stylesheet" href="css/ath-slides.css" type="text/css" />
    <link rel="stylesheet" href="css/ath-inferno-fonts.css" type="text/css" />
    <link rel="stylesheet" href="css/animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






class: center middle main-title section-title-1

# Effect size and power

.class-info[

**Session 5**

.light[MATH 80667A: Experimental Design and Statistical Methods &lt;br&gt;for Quantitative Research in Management &lt;br&gt;
HEC Montréal
]

]

---

name: outline
class: title title-inv-1

# Outline
--

.box-4.medium.sp-after-half[Effect sizes]

--

.box-7.medium.sp-after-half[Power]



---
layout: false
name: effect
class: center middle section-title section-title-4 animated fadeIn

# Effect size

---


class: title title-4
# Example from the OSC psychology replication



&gt; The key statistics provided in the paper to test the “depletion” hypothesis is the main effect of a one-way ANOVA with three experimental conditions and confirmatory information processing as the dependent variable ( `\(F(2, 82) = 4.05\)`, `\(p = 0.02\)`, `\(\eta^2 = 0.09\)`). Considering the original effect size and an alpha of `\(0.05\)` the sample size needed to achieve `\(90\)`% power is `\(132\)` subjects.

.small[
Replication report of Fischer, Greitemeyer, and Frey (2008, JPSP, Study 2) by E.M. Galliani
]


.box-inv-4.medium[Q: What is the sample size for given power?]

---

class: title title-4
# Measures of effects

`\(F\)`-statistics and `\(p\)`-values are not good summaries of effect size:

- the larger the sample size, the bigger the statistic

Instead use

- standardized differences/measures
- percentage of variability explained


Popularized in the handbook
&gt; Cohen, Jacob. Statistical Power Analysis for the Behavioral Sciences, 2nd ed., Routhledge, 1988.



---
class: title title-4
# Cohen's _d_

Standardized measure of effect (dimensionless=no units): 

e.g., for a comparison between two groups:

`$$\begin{align*}
d = \frac{\widehat{\mu}_1 - \widehat{\mu}_2}{\widehat{\sigma}}
\end{align*}$$`
where `\(\widehat{\sigma}\)` is the pooled variance.



.small[Note: a finite sample correction (Hedge) can be used.]

Cohen's _d_ is sometimes reported in terms of effect size
- small (_d=0.2_), medium (_d=0.5_) or large (_d=0.8_).

???

Note: this is not the `\(t\)`-statistic (the denominator is the estimated standard deviation, not the standard error of the mean

Note that there are multiple versions of Cohen's coefficients. 
These are the effects of the pwr package.
The small/medium/large effect size varies depending on the test! See the vignette of pwr for defaults.

---
class: title title-4
# Cohen's _f_

With more than two groups, compare the squared difference between overall mean and group mean assuming equal variance

`$$\begin{align*}
f^2 = \frac{1}{\widehat{\sigma}^2} \sum_{j=1}^k \frac{n_j}{n}(\widehat{\mu}_j - \widehat{\mu})^2,
\end{align*}$$`
a weighted sum of squared difference relative to the overall mean `\(\mu\)`.

For `\(k=2\)` groups, `\(f=d/2\)`.

---
class: title title-4
# `\(R^2\)` and `\(\eta^2\)`

Can break down the variability for sum of squares as 'total = within + between'.

Define the percentage of variability explained by `\(\text{effect}\)`.
`$$\eta^2 = \frac{\text{explained variability}}{\text{total variability}}$$`


The sample estimate is `\(R^2\)`, the coefficient of determination

&lt;!--
 Often, you see instead the following reported
 `$$R^2_p = \frac{\mathsf{SS}_{\text{effect}}}{\mathsf{SS}_{\text{error}}+\mathsf{SS}_{\text{effect}}}.$$`

For one-way ANOVA (no repeated measurements), the two are equivalent.
--&gt;

---
class: title title-4
# Coefficient of determination

For the balanced one-way ANOVA with exhaustive factors=all possible choices in the population, write

`$$\begin{align*}
R^2 = \frac{F\nu_1}{F\nu_1 + \nu_2}
\end{align*}$$`
where `\(\nu_1 = k-1\)` and `\(\nu_2 = n-k\)` for the one-way ANOVA. 


For the replication example, `$$R^2 = \frac{4.05\times 2}{4.05\times 2 + 84} = 0.088 \approx 0.09$$` as reported.


---
class: title title-4
# `\(\omega^2\)` square

Another (popular) measure of effect size.

For one-way ANOVA, a transformation of the `\(F\)`-statistic gives

`$$\begin{align*}
\omega^2 = \frac{\nu_1 (F-1)}{\nu_1(F-1)+n}
\end{align*}$$`

???

Since the `\(F\)` statistic is approximately 1 on average, this measure removes the average.

---

class: title title-4
# Comments on effect estimates

- There are two variants: population quantities (e.g., `\(\eta^2\)`) that depend on unknown parameters and sample estimates (e.g., `\(R^2\)`)
- In more complicated models, we can look at partial effects (proportion of variance relative to that of errors)
- Every effect size estimator is random (because its inputs are)
- Report confidence intervals with estimates whenever possible


---

layout: false
name: power
class: center middle section-title section-title-7 animated fadeIn

# Power

---

class: title title-7

# I cried power!

The null alternative corresponds to a single value: `\(\mu_1 = \cdots = \mu_K\)`, 
whereas there are infinitely many alternatives...

--


.pull-left[
  ![Power with small overlap](img/02/power1-1.png)
  .small.center[Power is the ability to detect when the null is false, for a given alternative (dashed).]
]
.pull-right[
  ![Power with large overlap](img/02/power2-1.png)
 .small.center[ Power is the area in white under the dashed curved, beyond the cutoff. ]
]

???
  
In which of the two figures is power the largest?

---

class: title title-7

# Parametrization of one-way ANOVA


.pull-left.box-inv-7[

group `\(j\)` has `\(n_j\)` observations

]

.pull-right.box-inv-7.sp-after-half[

population average of group `\(j\)` is `\(\mu_j\)`

]

We can parametrize the model in terms of the overall sample average,

`\begin{align*}
\mu = \frac{1}{n}\sum_{j=1}^K\sum_{i=1}^{n_j} \mu_j = \frac{1}{n}\sum_{j=1}^K n_j \mu_j,
\end{align*}`
where `\(n=n_1 + \cdots +n_K\)` is the total sample size.


---

class: title title-7

# What determines power?

Think in your head of potential factors.

--

1. The size of the effects, `\(\delta_1 = \mu_1-\mu\)`, `\(\ldots\)`, `\(\delta_K = \mu_K-\mu\)`
2. The background noise (intrinsic variability, `\(\sigma^2\)`)
3. The level of the test, `\(\alpha\)`
4. The sample size in each group, `\(n_j\)`
5. The choice of experimental design
6. The choice of test statistic

--

We focus on the interplay between 

.box-7.wide[

`\(\quad\)` effect size `\(\quad\)`  |  `\(\quad\)`  power `\(\quad\)`   |  `\(\quad\)`  sample size `\(\quad\)`

]




???

The level is fixed, but we may consider multiplicity correction within the power function.
The noise level is oftentimes intrinsic to the measurement .

---
class: title title-7

# Power and sample size calculations

Journals and grant agencies oftentimes require an estimate of the sample size needed for a study.

- large enough to pick-up effects of scientific interest (good signal-to-noise)
- efficient allocation of resources (don't waste time/money)

Same for study replication: how many participants needed?

---
class: title title-7
# Living in an alternative world

Recall that with `\(K\)` treatments (groups) `\(n\)` observations, the `\(F\)`-statistic is

`\begin{align*}
F =  \frac{\text{between sum of squares}/(K-1)}{\text{within sum of squares}/(n-K)}
\end{align*}`

The null distribution is `\(F(K-1, n-K)\)`.

The denominator is an estimator of `\(\sigma^2\)` under both the null and alternative.

So how does the _F_-test behaves under an alternative?



---
class: title title-7
# Numerator of the _F_-test

What happens to the numerator?
`$$\begin{align*}
\mathsf{E}(\text{between sum of squares}) = \sigma^2\{(K-1) + \Delta\}.
\end{align*}$$`
where
`$$\begin{align*}
\Delta = \dfrac{\sum_{j=1}^K n_j(\mu_j - \mu)^2}{\sigma^2} = nf^2.
\end{align*}$$`

Under the null hypothesis, `\(\mu_j=\mu\)` for `\(j=1, \ldots, K\)` and `\(\Delta=0\)`.

The greater `\(\Delta\)`, the further the mode (peak of the distribution) is from zero.

---
class: title title-7

# Noncentrality parameter and power

`$$\begin{align*}
\Delta = \dfrac{\sum_{j=1}^K n_j(\mu_j - \mu)^2}{\sigma^2}.
\end{align*}$$`

.box-inv-7.medium[When does power increase?]

What is the effect of an increase of the
- group sample size `\(n_1, \ldots, n_K\)`.
- variability `\(\sigma^2\)`.
- true mean difference `\(\mu_j - \mu\)`.

---
class: title title-7
# Noncentrality parameter

The distribution is `\(F(\nu_1, \nu_2, \Delta)\)` distribution with degrees of freedom `\(\nu_1\)` and `\(\nu_2\)` and noncentrality parameter `\(\Delta\)`.

.SMALL[
One-way ANOVA with `\(n\)` observations and `\(K\)` groups: `\(\nu_1 = K-1\)` and `\(\nu_2 = n-K\)`.
]

&lt;img src="05-slides_files/figure-html/power_curve-1.png" width="720" style="display: block; margin: auto;" /&gt;

.small[Note: the `\(F(\nu_1, \nu_2)\)` distribution is indistinguishable from `\(\chi^2(\nu_1)\)` for `\(\nu_2\)` large.
]

???

For other tests, parameters vary but the story is the same.

The plot shows the null and alternative distributions. The noncentral F is shifted to the right (mode = peak) and right skewed. The power is shaded in blue, the null distribution is shown in dashed lines.

---
class: title title-7
# Computing power

Given a value of `\(\Delta\)`, we can compute the tail probability as follows

1. Compute the cutoff point: the value under `\(\mathscr{H}_0\)` that leads to rejection at level `\(\alpha\)`. .box-inv-7.sp-before.sp-after[
`cutoff &lt;- qf(p = 1-alpha, df1 = df1, df2 = df2)`
]
2. Compute probability below the alternative curve, from the cutoff onwards.
.box-inv-7.sp-before[
`pf(q = cutoff,
    df1 = df1, 
    df2 = df2, 
    ncp = Delta, 
    lower.tail = FALSE)`
]


---
class: title title-7
# How do we compute the power

Assume that the design is balanced, meaning `\(n_1 = \cdots = n_k = n/k\)`.

Then,
`$$\begin{align*}
\Delta = \frac{n}{k\sigma^2}\sum_{j=1}^k(\mu_j-\mu)^2.
\end{align*}$$`

Plug-in `df1` `\(=k-1\)`, `df2` `\(=n-k\)` and `ncp` `\(=\Delta\)` for fixed mean difference, level and  number of groups in the formulas of the previous slide.

---
class: title title-7
# Power curves
.pull-left[


```r
library(pwr)
power_curve &lt;- 
 pwr.anova.test(
  f = sqrt(0.09/(1-0.09)), 
  k = 3, 
  power = 0.9,
  sig.level = 0.05)
plot(power_curve)
```

.tiny[

Convert `\(\eta^2\)` to Cohen's `\(f\)` (the effect size reported in `pwr`) via `\(f^2=\eta^2/(1-\eta^2)\)`. Explained later in the slides.

]

]
.pull-right[
&lt;img src="05-slides_files/figure-html/powercurvefig-1.png" width="504" style="display: block; margin: auto;" /&gt;
]
---
class: title title-7
# Power calculations with unknowns

Need to specify the following parameters: 

.box-inv-7.sp-after-half[

Level `\(\alpha\)` (usually 5%)

]
.center[adjust if you plan to correct for multiple testing!
]
.box-inv-7.sp-before.sp-after-half[

Variance `\(\sigma^2\)`

]
run a pilot study or look up plausible values from the literature
.box-inv-7.sp-before.sp-after-half[

Mean difference size `\(\mu_i - \mu\)`
]

---
class: title title-7
# Estimating mean differences

If you care for a difference of `\(D\)` units between groups, the smallest value of `\(\Delta\)` (**worst case analysis**) is when 

- one group has mean difference `\(\mu_1 - \mu = -D/2\)`, 
- another has `\(\mu_2 - \mu = D/2\)` and 
- the rest with zero difference.


With a balanced design, we thus get 
`$$\begin{align*}
\Delta = \frac{n}{k\sigma^2}\sum_{j=1}^{k}(\mu_j-\mu)^2 = \frac{n}{k\sigma^2}\left(\frac{D^2}{4} + \frac{D^2}{4}\right) = \frac{nD^2}{2k\sigma^2}.
\end{align*}$$`

---
class: title title-7
# Effect size estimates

.box-inv-7.large[WARNING!]

Most effects reported in the literature are severely inflated.

.box-7[Publication bias &amp; the file drawer problem]

Estimates reported in meta-analysis, etc. are not reliable. Use scientific knowledge

Replication reveal serious need for shrinkage.

The estimated effects size also have uncertainty: thus report confidence intervals.

???

Recall the file drawer problem: most studies with small effects lead to *non significant results* and are not published. So the reported effects are larger than expected.

---
class: title title-7
# Beware of small samples

Better to do a large replication than multiple small studies. 

Otherwise, you risk being in this situation:

&lt;img src="img/05/you-have-no-power-here.jpg" width="50%" style="display: block; margin: auto;" /&gt;

---
class: title title-7

# Observed (post-hoc) power

Sometimes, the estimated values of the effect size, etc. are used as plug-in.

The (estimated) effect size in studies are noisy! 


The post-hoc power estimate is also noisy and typically overoptimistic.

.box-inv-7[Statistical fallacy]

Because we reject a null doesn't mean the alternative is true.

When is this relevant? If the observed difference seem important (large), but there isn't enough evidence (too low signal-to-noise).

???

Not recommended unless the observed differences among
the means seem important in practice but
are not statistically significant


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
