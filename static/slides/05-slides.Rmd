---
title: "Power, effects and model assumptions"
author: "Léo Belzile"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: "libs"
    chakra: "libs/remark-latest.min.js"
    css: ["default", "css/ath-slides.css", "css/ath-inferno-fonts.css", "css/animate.css"]
    seal: false
    anchor_sections: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = "center")
```
```{r packages-data, echo = FALSE, include=FALSE}
library(tidyverse)
library(patchwork)
```
```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view","freezeframe","panelset"))
# xaringanExtra::use_clipboard()
xaringanExtra::use_broadcast()
```

class: center middle main-title section-title-1

# Power and model assumptions

.class-info[

**Session 5**

.light[MATH 80667A: Experimental Design and Statistical Methods <br>for Quantitative Research in Management <br>
HEC Montréal
]

]

---

name: outline
class: title title-inv-1

# Outline
--

.box-7.medium.sp-after-half[Power]

--

.box-3.medium.sp-after-half[Effect and sample sizes]

--


.box-2.medium.sp-after-half[Model assumptions]


---

layout: false
name: power
class: center middle section-title section-title-7 animated fadeIn

# Power

---

class: title title-7

# I cried power!

The null alternative corresponds to a single value: $\mu_1 = \cdots = \mu_K$, 
whereas there are infinitely many alternatives...

--


.pull-left[
  ![Power with small overlap](img/02/power1-1.png)
  .small.center[Power is the ability to detect when the null is false, for a given alternative (dashed).]
]
.pull-right[
  ![Power with large overlap](img/02/power2-1.png)
 .small.center[ Power is the area in white under the dashed curved, beyond the cutoff. ]
]

???
  
In which of the two figures is power the largest?

---

class: title title-7

# Parametrization of one-way ANOVA


.pull-left.box-inv-7[

group $j$ has $n_j$ observations

]

.pull-right.box-inv-7.sp-after-half[

population average of group $j$ is $\mu_j$

]

We can parametrize the model in terms of the overall sample average,

\begin{align*}
\mu = \frac{1}{n}\sum_{j=1}^K\sum_{i=1}^{n_j} \mu_j = \frac{1}{n}\sum_{j=1}^K n_j \mu_j,
\end{align*}
where $n=n_1 + \cdots +n_K$ is the total sample size.


---

class: title title-7

# What determines power?

Think in your head of potential factors.

--

1. The size of the effects, $\delta_1 = \mu_1-\mu$, $\ldots$, $\delta_K = \mu_K-\mu$
2. The background noise (intrinsic variability, $\sigma^2$)
3. The level of the test, $\alpha$
4. The sample size in each group, $n_j$
5. The choice of experimental design
6. The choice of test statistic

--

We focus on the interplay between 

.box-7.wide[

$\quad$ effect size $\quad$  |  $\quad$  power $\quad$   |  $\quad$  sample size $\quad$

]




???

The level is fixed, but we may consider multiplicity correction within the power function.
The noise level is oftentimes intrinsic to the measurement .

---
class: title title-7

# Power and sample size calculations

Journals and grant agencies oftentimes require an estimate of the sample size needed for a study.

- large enough to pick-up effects of scientific interest (good signal-to-noise)
- efficient allocation of resources (don't waste time/money)

Same for study replication: how many participants needed?

---
class: title title-7
# Living in an alternative world

Recall that with $K$ treatments (groups) $n$ observations, the $F$-statistic is

\begin{align*}
F =  \frac{\text{between sum of squares}/(K-1)}{\text{within sum of squares}/(n-K)}
\end{align*}

The null distribution is $F(K-1, n-K)$.

The denominator is an estimator of $\sigma^2$ under both the null and alternative.

So how does the _F_-test behaves under an alternative?



---
class: title title-7
# Numerator of the _F_-test

What happens to the numerator?
$$\begin{align*}
\mathsf{E}(\text{between sum of squares}) = \sigma^2\{(K-1) + \Delta\}.
\end{align*}$$
where
$$\begin{align*}
\Delta = \dfrac{\sum_{j=1}^K n_j(\mu_j - \mu)^2}{\sigma^2}.
\end{align*}$$

Under the null hypothesis, $\mu_j=\mu$ for $j=1, \ldots, K$ and $\Delta=0$.

The greater $\Delta$, the further the mode (peak of the distribution) is from zero.

---
class: title title-7

# Noncentrality parameter and power

$$\begin{align*}
\Delta = \dfrac{\sum_{j=1}^K n_j(\mu_j - \mu)^2}{\sigma^2}.
\end{align*}$$

.box-inv-7.medium[When does power increase?]

What is the effect of an increase of the
- group sample size $n_1, \ldots, n_K$.
- variability $\sigma^2$.
- true mean difference $\mu_j - \mu$.

---
class: title title-7
# Noncentrality parameter

The distribution is $F(\nu_1, \nu_2, \Delta)$ distribution with degrees of freedom $\nu_1$ and $\nu_2$ and noncentrality parameter $\Delta$.

.SMALL[
One-way ANOVA with $n$ observations and $K$ groups: $\nu_1 = K-1$ and $\nu_2 = n-K$.
]

```{r power_curve, echo = FALSE, eval = TRUE,  fig.width = 10, fig.height = 4}
library(ggplot2)
df1 <- 4; df2 <- 40; ncp = 3
ggplot() +
  coord_cartesian(xlim = c(0,7.5), 
                  ylim = c(0, 1), 
                  expand = FALSE) +
  stat_function(fun = df, 
                args = list(ncp = ncp, 
                            df1 = df1, 
                            df2 = df2), 
                xlim = c(qf(0.95, 
                            df1 = df1, 
                            df2 = df2), 10),
                geom = "area", 
                fill = "blue", 
                alpha = 0.2) +
  stat_function(fun = df, 
                args = list(df1 = df1, 
                            df2 = df2, 
                            ncp = ncp), 
                xlim = c(0, 10)) +
  stat_function(fun = df, 
                n = 1000, 
                args = list(df1 = df1, 
                            df2 = df2), 
                xlim = c(0,10),
                linetype = 2) +
  geom_vline(xintercept = qf(0.95, 
                             df1 = df1, 
                             df2 = df2), 
             linetype = 2) +
  annotate(geom="text", 
             x=1, y=0.7, 
             label="H0: F(4,40)") +
  annotate(geom="text", 
             x=2, y=0.35, 
             label="F(4,40, 3)") +
  ylab("density") +
  xlab("F statistic") + 
  theme_classic()
```

.small[Note: the $F(\nu_1, \nu_2)$ distribution is indistinguishable from $\chi^2(\nu_1)$ for $\nu_2$ large.
]

???

For other tests, parameters vary but the story is the same.

The plot shows the null and alternative distributions. The noncentral F is shifted to the right (mode = peak) and right skewed. The power is shaded in blue, the null distribution is shown in dashed lines.

---
class: title title-7
# Computing power

Given a value of $\Delta$, we can compute the tail probability as follows

1. Compute the cutoff point: the value under $\mathscr{H}_0$ that leads to rejection at level $\alpha$. .box-inv-7.sp-before.sp-after[
`cutoff <- qf(p = 1-alpha, df1 = df1, df2 = df2)`
]
2. Compute probability below the alternative curve, from the cutoff onwards.
.box-inv-7.sp-before[
`pf(q = cutoff,
    df1 = df1, 
    df2 = df2, 
    ncp = Delta, 
    lower.tail = FALSE)`
]

---
class: title title-7
# Example from the OSC psychology replication



> The key statistics provided in the paper to test the “depletion” hypothesis is the main effect of a one-way ANOVA with three experimental conditions and confirmatory information processing as the dependent variable ( $F(2, 82) = 4.05$, $p = 0.02$, $\eta^2 = 0.09$). Considering the original effect size and an alpha of $0.05$ the sample
size needed to achieve $90$% power is $132$ subjects.

.small[
Replication report of Fischer, Greitemeyer, and Frey (2008, JPSP, Study 2) by E.M. Galliani
]


.box-inv-7.medium[Q: What is the sample size for given power?]

---
class: title title-7
# How do we compute the power

Assume that the design is balanced, meaning $n_1 = \cdots = n_k = n/k$.

Then,
$$\begin{align*}
\Delta = \frac{n}{k\sigma^2}\sum_{j=1}^k(\mu_j-\mu)^2.
\end{align*}$$

Plug-in `df1` $=k-1$, `df2` $=n-k$ and `ncp` $=\Delta$ for fixed mean difference, level and  number of groups in the formulas of the previous slide.

---
class: title title-7
# Power curves
.pull-left[

```{r powercurve, eval = FALSE, echo = TRUE,}
library(pwr)
power_curve <- 
 pwr.anova.test(
  f = sqrt(0.09/(1-0.09)), 
  k = 3, 
  power = 0.9,
  sig.level = 0.05)
plot(power_curve)
```

.tiny[

Convert $\eta^2$ to Cohen's $f$ (the effect size reported in `pwr`) via $f^2=\eta^2/(1-\eta^2)$. Explained later in the slides.

]

]
.pull-right[
```{r powercurvefig, echo = FALSE, eval = TRUE}
library(pwr)
power_curve <- pwr.anova.test(
  f = round(sqrt(0.09/(1-0.09)),3), 
  k = 3, 
  power = 0.9)
plot(power_curve, xlab="sample size per group") + theme_minimal() + ylab("power")
```
]
---
class: title title-7
# Power calculations with unknowns

Need to specify the following parameters: 

.box-inv-7.sp-after-half[

Level $\alpha$ (usually 5%)

]
.center[adjust if you plan to correct for multiple testing!
]
.box-inv-7.sp-before.sp-after-half[

Variance $\sigma^2$

]
run a pilot study or look up plausible values from the literature
.box-inv-7.sp-before.sp-after-half[

Mean difference size $\mu_i - \mu$
]

---
class: title title-7
# Estimating mean differences

If you care for a difference of $D$ units between groups, the smallest value of $\Delta$ (**worst case analysis**) is when 

- one group has mean difference $\mu_1 - \mu = -D/2$, 
- another has $\mu_2 - \mu = D/2$ and 
- the rest with zero difference.


With a balanced design, we thus get 
$$\begin{align*}
\Delta = \frac{n}{k\sigma^2}\sum_{j=1}^{k}(\mu_j-\mu)^2 = \frac{n}{k\sigma^2}\left(\frac{D^2}{4} + \frac{D^2}{4}\right) = \frac{nD^2}{2k\sigma^2}.
\end{align*}$$

---
class: title title-7
# Effect size estimates

.box-inv-7.large[WARNING!]

Most effects reported in the literature are severely inflated.

.box-7[Publication bias & the file drawer problem]

Estimates reported in meta-analysis, etc. are not reliable. Use scientific knowledge

Replication reveal serious need for shrinkage.

The estimated effects size also have uncertainty: thus report confidence intervals.

???

Recall the file drawer problem: most studies with small effects lead to *non significant results* and are not published. So the reported effects are larger than expected.

---
class: title title-7
# Beware of small samples

Better to do a large replication than multiple small studies. 

Otherwise, you risk being in this situation:

```{r plot, echo = FALSE, out.width='50%'}
knitr::include_graphics("img/05/you-have-no-power-here.jpg")
```

---
class: title title-7

# Observed (post-hoc) power

Sometimes, the estimated values of the effect size, etc. are used as plug-in.

The (estimated) effect size in studies are noisy! 


The post-hoc power estimate is also noisy and typically overoptimistic.

.box-inv-7[Statistical fallacy]

Because we reject a null doesn't mean the alternative is true.

When is this relevant? If the observed difference seem important (large), but there isn't enough evidence (too low signal-to-noise).

???

Not recommended unless the observed differences among
the means seem important in practice but
are not statistically significant

---
layout: false
name: effect
class: center middle section-title section-title-4 animated fadeIn

# Effect size

---
class: title title-4
# Measures of effects

Multiple alternatives

- standardized differences/measures
- percentage of variability explained (ratio of sum of squares or coefficients of determination).

They are all interrelated, but different people have different preferences.

Popularized in the handbook
> Cohen, Jacob. Statistical Power Analysis for the Behavioral Sciences, 2nd ed., Routhledge, 1988.



---
class: title title-4
# Cohen's _d_

Popular standardized measure of effect (dimensionless=no units): 

e.g., for a two-sample $t$-test between groups (comparing two means):

$$\begin{align*}
d = \frac{\widehat{\mu}_1 - \widehat{\mu}_2}{\widehat{\sigma}}
\end{align*}$$
where $\widehat{\sigma}$ is the pooled variance.
.small[Note: a finite sample correction (Hedge) can be used.]

Cohen's $d$ is sometimes reported in terms of effect size
- small ( $d=0.2$ ), medium ( $d=0.5$ ) or large ( $d=0.8$ ) effect: these values change from one test to the next (above is for the two-sample _t_-test).

???

Note that there are multiple versions of Cohen's coefficients. 
These are the effects of the pwr package.
The small/medium/large effect size varies depending on the test! See the vignette of pwr for defaults.

---
class: title title-4
# Eta-squared

Can break down the variability for sum of squares as 'total = within + between'.
Define the percentage of variability explained by $\text{effect}$.
$$\eta^2 = \frac{\mathsf{SS}_{\text{effect}}}{\mathsf{SS}_{\text{total}}},$$
Problem: this depends on the variability of the measurement. Often, in more complex design, you see instead the following reported
$$\eta^2 = \frac{\mathsf{SS}_{\text{effect}}}{\mathsf{SS}_{\text{error}}+\mathsf{SS}_{\text{effect}}}.$$

For one-way ANOVA (no repeated measurements), the two are equivalent.

---
class: title title-4
# Eta-squared

For the balanced one-way ANOVA with exhaustive factors=all possible choices in the population, write

$$\begin{align*}
\eta^2 = \frac{F\nu_1}{F\nu_1 + \nu_2}
\end{align*}$$

For the replication example, $$\eta^2 = \frac{4.05\times 2}{4.05\times 2 + 84} = 0.088 \approx 0.09$$


---
class: title title-4
# Omega square

Yet another measure of effect size.

For one-way ANOVA, a transformation of the $F$-statistic gives

$$\begin{align*}
\omega^2 = \frac{\nu_1 (F-1)}{\nu_1(F-1)+n}
\end{align*}$$

Partial versions for more complex designs, etc.

.box-inv-4[Uncertainty matters!]

Every effect size is random (because inputs are)

Report confidence intervals with estimates.

---
layout: false
name: model-assumptions
class: center middle section-title section-title-2 animated fadeIn

# Model assumptions


